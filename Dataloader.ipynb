{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import *\n",
    "import Setting as _C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodities = {\n",
    "            'rb':{'multiplier':10,'mintick':1,'exchange':'SHF'},\n",
    "            'hc':{'multiplier':10,'mintick':1,'exchange':'SHF'},\n",
    "            'i':{'multiplier':100,'mintick':0.5,'exchange':'DCE'},\n",
    "            'm':{'multiplier':10,'mintick':1,'exchange':'DCE'},\n",
    "            'pp':{'multiplier':5,'mintick':1,'exchange':'DCE'},\n",
    "            'MA':{'multiplier':10,'mintick':1,'exchange':'CZC'},\n",
    "            'bu':{'multiplier':10,'mintick':2,'exchange':'SHF'},\n",
    "            'l':{'multiplier':5,'mintick':5,'exchange':'DCE'},\n",
    "            'p':{'multiplier':10,'mintick':2,'exchange':'DCE'},\n",
    "            'v':{'multiplier':5,'mintick':5,'exchange':'DCE'},\n",
    "            'CF':{'multiplier':5,'mintick':5,'exchange':'CZC'},\n",
    "            'OI':{'multiplier':10,'mintick':1,'exchange':'CZC'},\n",
    "            'SR':{'multiplier':10,'mintick':1,'exchange':'CZC'},\n",
    "            'TA':{'multiplier':5,'mintick':2,'exchange':'CZC'},\n",
    "            'SA':{'multiplier':20,'mintick':1,'exchange':'CZC'},\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Download_data(timeframe, start_date, end_date):\n",
    "    F_data = {}\n",
    "    VTD = []\n",
    "\n",
    "    if timeframe == '1min':\n",
    "        for symbol in tqdm(commodities.keys(), desc='Downloading API 1 min data'):\n",
    "            c = f\"R.CN.{commodities[symbol]['exchange']}.{symbol}.0004\"\n",
    "\n",
    "            com_1min = get_price(c, start_date, end_date, 'minute1')\n",
    "            com_1min[['OPEN', 'HIGH', 'CLOSE', 'LOW']] = com_1min[['OPEN', 'HIGH', 'CLOSE', 'LOW']].astype('float64')\n",
    "            com_1min[['SYMBOL', 'CLOCK']] =  com_1min[['SYMBOL', 'CLOCK']].astype('string')\n",
    "\n",
    "            com_1min['DATE'] = com_1min['CLOCK'].apply(lambda x: x[:10])\n",
    "            com_vtd = com_1min['DATE'].loc[~com_1min['DATE'].duplicated()].to_list()\n",
    "            VTD = com_vtd if len(com_vtd) > len(VTD) else VTD\n",
    "\n",
    "            F_data[symbol] = com_1min\n",
    "\n",
    "        F_data['VTD'] = VTD\n",
    "\n",
    "        with open('dataset/F_data_1min.pkl', 'wb') as f:\n",
    "            pickle.dump(F_data, f)\n",
    "\n",
    "    elif timeframe == '5min':\n",
    "        for symbol in tqdm(commodities.keys(), desc='Downloading API 5 min data'):\n",
    "            c = f\"R.CN.{commodities[symbol]['exchange']}.{symbol}.0004\"\n",
    "\n",
    "            com_5min = get_price(c, start_date, end_date, 'minute5')\n",
    "            com_5min[['OPEN', 'HIGH', 'CLOSE', 'LOW']] = com_5min[['OPEN', 'HIGH', 'CLOSE', 'LOW']].astype('float64')\n",
    "            com_5min[['SYMBOL', 'CLOCK']] =  com_5min[['SYMBOL', 'CLOCK']].astype('string')\n",
    "\n",
    "            com_5min['DATE'] = com_5min['CLOCK'].apply(lambda x: x[:10])\n",
    "            com_vtd = com_5min['DATE'].loc[~com_5min['DATE'].duplicated()].to_list()\n",
    "            VTD = com_vtd if len(com_vtd) > len(VTD) else VTD\n",
    "\n",
    "            F_data[symbol] = com_5min\n",
    "\n",
    "        F_data['VTD'] = VTD\n",
    "\n",
    "        with open('dataset/F_data_5min.pkl', 'wb') as f:\n",
    "            pickle.dump(F_data, f)\n",
    "\n",
    "    elif timeframe == '15min':\n",
    "        for symbol in tqdm(commodities.keys(), desc='Downloading API 15 min data'):\n",
    "            c = f\"R.CN.{commodities[symbol]['exchange']}.{symbol}.0004\"\n",
    "\n",
    "            com_15min = get_price(c, start_date, end_date, 'minute15')\n",
    "            com_15min[['OPEN', 'HIGH', 'CLOSE', 'LOW']] = com_15min[['OPEN', 'HIGH', 'CLOSE', 'LOW']].astype('float64')\n",
    "            com_15min[['SYMBOL', 'CLOCK']] =  com_15min[['SYMBOL', 'CLOCK']].astype('string')\n",
    "\n",
    "            com_15min['DATE'] = com_15min['CLOCK'].apply(lambda x: x[:10])\n",
    "            com_vtd = com_15min['DATE'].loc[~com_15min['DATE'].duplicated()].to_list()\n",
    "            VTD = com_vtd if len(com_vtd) > len(VTD) else VTD\n",
    "\n",
    "            F_data[symbol] = com_15min\n",
    "\n",
    "        F_data['VTD'] = VTD\n",
    "\n",
    "        with open('dataset/F_data_15min.pkl', 'wb') as f:\n",
    "            pickle.dump(F_data, f)\n",
    "\n",
    "    elif timeframe == 'D':\n",
    "        for symbol in tqdm(commodities.keys(), desc='Downloading API Daily data'):\n",
    "            c = f\"R.CN.{commodities[symbol]['exchange']}.{symbol}.0004\"\n",
    "\n",
    "            com_D = get_price(c, start_date, end_date) # API default timeframe is daily data\n",
    "            com_D[['OPEN', 'HIGH', 'CLOSE', 'LOW']] = com_D[['OPEN', 'HIGH', 'CLOSE', 'LOW']].astype('float64')\n",
    "            com_D[['SYMBOL', 'CLOCK']] =  com_D[['SYMBOL', 'CLOCK']].astype('string')\n",
    "\n",
    "            com_D['DATE'] = com_D['CLOCK'].apply(lambda x: x[:10])\n",
    "            com_vtd = com_D['DATE'].loc[~com_D['DATE'].duplicated()].to_list()\n",
    "            VTD = com_vtd if len(com_vtd) > len(VTD) else VTD\n",
    "\n",
    "            F_data[symbol] = com_D\n",
    "\n",
    "        F_data['VTD'] = VTD\n",
    "\n",
    "        with open('dataset/F_data_D.pkl', 'wb') as f:\n",
    "            pickle.dump(F_data, f)\n",
    "    else: \n",
    "        print(\"Non Valid TimeFrame in ['1min', '5min', '15min', 'D']\")\n",
    "\n",
    "    return F_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset(timeframe, start_date='2010-01-01', end_date='2022-08-19'):\n",
    "    T_delta = {'1min': 1, '5min': 5, '15min': 15, 'D': 1440}\n",
    "    F_data = {}\n",
    "    local_file = f'F_data_{timeframe}.pkl'\n",
    "    if local_file in os.listdir('dataset'):\n",
    "        F_data = pd.read_pickle('dataset/'+local_file)\n",
    "        VTD = F_data['VTD']\n",
    "\n",
    "        start_date_delta = (pd.to_datetime(start_date) - pd.to_datetime(VTD[0])).total_seconds()/(60*60*24) # s->min->h->d\n",
    "        end_date_delta = (pd.to_datetime(end_date) - pd.to_datetime(VTD[-1])).total_seconds()/(60*60*24) # s->min->h->d\n",
    "\n",
    "        if (np.abs(start_date_delta) < 5) and (np.abs(end_date_delta) < 5):\n",
    "            time_delta = (pd.to_datetime(F_data['rb']['CLOCK'][1])-pd.to_datetime(F_data['rb']['CLOCK'][0])).total_seconds()/60\n",
    "\n",
    "            if time_delta != T_delta[timeframe]:\n",
    "                print(f'Error: Time Frame is not {timeframe}!')\n",
    "                F_data = Download_data(timeframe, start_date, end_date)\n",
    "            else:\n",
    "                print(f\"Using Local Data | BackTest VTD: {VTD[0]}--{VTD[-1]}\")\n",
    "\n",
    "        else:\n",
    "            print(f'VTD Bias | Local Data VTD: {VTD[0]}--{VTD[-1]}')\n",
    "            F_data = Download_data(timeframe, start_date, end_date)\n",
    "    else:\n",
    "        print(f'No Local Data of {timeframe}')\n",
    "        F_data = Download_data(timeframe, start_date, end_date)\n",
    "\n",
    "    return F_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
